{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff58753a",
   "metadata": {},
   "source": [
    "# üìì Linear Regression from Scratch\n",
    "\n",
    "### üéØ Objective\n",
    "- Implement a linear regression model using gradient descent. \n",
    "- Derive the gradient updates, write a scikit-learn-like class, and evaluate using synthetic data.\n",
    "- Compare the result of the same with library code output\n",
    "- Use R2-Score and Mean Absolute Percentage error as Performance metric on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b08dfe6",
   "metadata": {},
   "source": [
    "## üìä Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7bb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Synthetic Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1353713",
   "metadata": {},
   "source": [
    "## Do Train-Test Split (75%-25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bd95d",
   "metadata": {},
   "source": [
    "## Do the Linear Regression with Scikit-Learn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e787214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd80e4c",
   "metadata": {},
   "source": [
    "## Do Ridge and Lasso Regression and Compare the evaluation metrics in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1313e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90959c9a",
   "metadata": {},
   "source": [
    "## Custom Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336101a1",
   "metadata": {},
   "source": [
    "## üßÆ Derive the Gradient Updates\n",
    "Use the chain rule to derive the gradients of the loss function (Mean Square Error):\n",
    "\n",
    "$$ \\text{Loss} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - (mx_i + c))^2 $$\n",
    "\n",
    "Derive:\n",
    "- ‚àÇLoss/‚àÇm\n",
    "- ‚àÇLoss/‚àÇc\n",
    "\n",
    "Write the derivation here/add screenshot of your derivation here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d4781",
   "metadata": {},
   "source": [
    "## üß† Custom Linear Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyLinearRegression:\n",
    "    def __init__(self):\n",
    "       pass\n",
    "\n",
    "    def fit(self, X, y, lr=0.01, n_iters=1000):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y, lr=0.01, n_iters=1000):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c59cd7",
   "metadata": {},
   "source": [
    "## üîÅ Train the Model and Visualize the Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MyLinearRegression()\n",
    "model.fit(X_train, y_train, lr=0.1, n_iters=100)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "plt.scatter(X_test, y_test, label=\"Data\")\n",
    "plt.plot(X_test, y_pred, color=\"red\", label=\"Model\")\n",
    "plt.legend()\n",
    "plt.title(\"Linear Regression Fit\")\n",
    "plt.show()\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Learned coefficients (m, c):\", model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ef2cd",
   "metadata": {},
   "source": [
    "## üìâ Plot the Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac04f98",
   "metadata": {},
   "source": [
    "## üåü Bonus Task: Stochastic Gradient Descent\n",
    "Implement a class `MyLinearRegressionSGD` that uses one training sample per iteration to update weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfaa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve while using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136f0a7",
   "metadata": {},
   "source": [
    "## Visualize the prediction result of Library version and Custom regression code created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3545d",
   "metadata": {},
   "source": [
    "## ‚úÖ Checklist\n",
    "- [ ] Did linear regression using scikit-learn API\n",
    "- [ ] Did Ridge and Lasso regression and compiled the result (R2 and MAPE) as a table\n",
    "- [ ] Derived gradients using chain rule\n",
    "- [ ] Implemented custom Linear Regression class\n",
    "- [ ] Trained using gradient descent\n",
    "- [ ] Visualized predictions and loss\n",
    "- [ ] Implemented stochastic gradient descent (bonus)\n",
    "- [ ] Visualized predictions and loss for stochastic gradient descent (bonus)\n",
    "- [ ] Visualize the prediction result of Library version and custom version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
