{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OBVGDjrHbOD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"churn_data.csv\")\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_cols = ['number_of_projects', 'work_accident', 'churn',\n",
        "                    'promotion', 'department','satisfaction','evaluation', 'salary',\n",
        "                    'average_montly_hours','time_spend_company']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Classifiers\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier()\n",
        "}\n",
        "\n",
        "# Evaluate and store results\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results.append({\n",
        "        \"Model Name\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1-Score\": f1_score(y_test, y_pred)\n",
        "    })\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results).round(4)\n",
        "\n",
        "# Determine best model based on F1-score\n",
        "best_model = results_df.loc[results_df['F1-Score'].idxmax()]\n",
        "\n",
        "# Display results\n",
        "print(\"\\nModel Comparison Table:\")\n",
        "print(results_df)\n",
        "print(\"\\nBest Model Based on F1-Score:\")\n",
        "print(best_model)"
      ]
    }
  ]
}