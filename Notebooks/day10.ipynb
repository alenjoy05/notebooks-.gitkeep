{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4d663d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"beer-servings.csv\")\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3eaae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeebc35",
   "metadata": {},
   "source": [
    "splitting numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1208edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = data.select_dtypes(include=\"number\")\n",
    "cat_df = data.select_dtypes(include=\"object\")\n",
    "\n",
    "print(num_df)\n",
    "print(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e35175b",
   "metadata": {},
   "source": [
    "Histogram of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b14fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = num_df.columns.tolist()\n",
    "print(num_cols)\n",
    "for col in num_cols:\n",
    "    plt.hist(num_df[col].dropna())\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    num_df[col] = num_df[col].fillna(num_df[col].median())\n",
    "    \n",
    "print(num_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(num_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_outliers(df, column_name):\n",
    "    q1 = df[column_name].quantile(0.25)\n",
    "    q3 = df[column_name].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = q3 + 1.5 *iqr\n",
    "    lower_bound = q1 - 1.5 *iqr\n",
    "    df[column_name] = df[column_name].clip(upper=upper_bound)\n",
    "    df[column_name] = df[column_name].clip(lower=lower_bound)\n",
    "    return df[column_name]\n",
    "\n",
    "for col in num_cols:\n",
    "    num_df[col] = clip_outliers(num_df, col)\n",
    "    \n",
    "plt.boxplot(num_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6365ee",
   "metadata": {},
   "source": [
    "Min max scaling and standard scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13027b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min max scaling and standard scaling without library\n",
    "for col in num_cols[:-1]:\n",
    "    num_df[col] = (num_df[col]- num_df[col.min()])/(num_df[col].max()- num_df[col].min())\n",
    "    \n",
    "for col in num_cols[:-1]:\n",
    "    num_df[col] = (num_df[col]- num_df[col].mean())/num_df[col].std()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix max and standard scaling with library\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "num_df = min_max_scaler.fit_transform(num_df)\n",
    "print(num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix max and standard scaling with library\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "num_df = std_scaler.fit_transform(num_df)\n",
    "print(num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950dcbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the min max and standard as files\n",
    "\n",
    "import pickle\n",
    "with open(\"min_max_scaler.pkl\", \"wb\") as f:\n",
    "   pickle.dump(min_max_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"min_max_scaler.pkl\", \"rb\") as f:\n",
    "    min_max_scaler = pickle.load(f)\n",
    "\n",
    "print(\"Min:\", min_max_scaler.min_)\n",
    "print(\"Scale:\", min_max_scaler.scale_)\n",
    "print(\"Feature range:\", min_max_scaler.feature_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.array([[200, 100, 300, 150]])\n",
    "test_output = min_max_scaler.transform(test_input)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = {'color': ['yellow', 'green', 'blue', 'yellow', 'green']}\n",
    "df = pd.DataFrame(data)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_data = encoder.fit_transform(df[['color']])\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=['blue', 'green', 'yellow'])\n",
    "final_df = pd.concat([df, encoded_df] , axis=1)\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = cat_df.columns.tolist()\n",
    "for col in cat_cols:\n",
    "    encoder = LabelEncoder()\n",
    "    cat_df[col] = encoder.fit_transform(cat_df[col])\n",
    "print(cat_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f876624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to use the original dataframe from 'data' (beer-servings.csv)\n",
    "# and not the example 'final_df' from the color encoding example\n",
    "\n",
    "# First, let's reconstruct a DataFrame from the scaled numpy array for easier column access\n",
    "num_df_scaled = pd.DataFrame(num_df, columns=num_cols)\n",
    "\n",
    "y = num_df_scaled[\"total_litres_of_pure_alcohol\"]\n",
    "X = num_df_scaled.drop(\"total_litres_of_pure_alcohol\", axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
